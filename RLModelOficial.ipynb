{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando a base de dados\n",
    "df = pd.read_csv('C:/Users/AMD/Desktop/DESKTOP ANTIGA/Área de trabalho/Leandro/MBA USP/TCC/Modelos/Testes/credit_risk_dataset.csv', delimiter=';')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a existência de dados espúrios\n",
    "print('\\nContando os 144 na amostra:\\n')\n",
    "print(f'Idade fora do normal: {(df[\"person_age\"]==144).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluindo dados espúrios\n",
    "print(f'Linhas antes da exclusão: {len(df)}')\n",
    "excluir_idade_144 = df.index[df.person_age == 144].tolist()\n",
    "temp = excluir_idade_144\n",
    "cred_risk = df.drop(df.index[temp])\n",
    "classe_0 = len(cred_risk[cred_risk['loan_status'] == 0])\n",
    "classe_1 = len(cred_risk[cred_risk['loan_status'] == 1])\n",
    "print(f'Linhas após a exclusão: {len(cred_risk)}')\n",
    "print(f'Pessoas em dia na amostra: {classe_0} ({(classe_0 * 100 / (classe_0 + classe_1)):.2f}%)')\n",
    "print(f'Pessoas em dia na amostra: {classe_1} ({(classe_1 * 100 / (classe_0 + classe_1)):.2f}%)')\n",
    "cred_risk.to_csv('C:/Users/AMD/Desktop/DESKTOP ANTIGA/Área de trabalho/Leandro/MBA USP/TCC/Modelos/Testes/crg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = pd.read_csv('C:/Users/AMD/Desktop/DESKTOP ANTIGA/Área de trabalho/Leandro/MBA USP/TCC/Modelos/Testes/crg.csv', delimiter=',')\n",
    "cr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluindo dados espúrios\n",
    "print(f'Linhas antes da exclusão: {len(cr)}')\n",
    "excluir_idade_123 = cr.index[cr.person_age == 123].tolist()\n",
    "temp2 = excluir_idade_123\n",
    "cred_risk3 = cr.drop(cr.index[temp2])\n",
    "classe_0 = len(cred_risk3[cred_risk3['loan_status'] == 0])\n",
    "classe_1 = len(cred_risk3[cred_risk3['loan_status'] == 1])\n",
    "print(f'Linhas após a exclusão: {len(cred_risk3)}')\n",
    "print(f'Pessoas em dia na amostra: {classe_0} ({(classe_0 * 100 / (classe_0 + classe_1)):.2f}%)')\n",
    "print(f'Pessoas em dia na amostra: {classe_1} ({(classe_1 * 100 / (classe_0 + classe_1)):.2f}%)')\n",
    "cred_risk3.to_csv('C:/Users/AMD/Desktop/DESKTOP ANTIGA/Área de trabalho/Leandro/MBA USP/TCC/Modelos/Testes/crisk_geral.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crisk = pd.read_csv('C:/Users/AMD/Desktop/DESKTOP ANTIGA/Área de trabalho/Leandro/MBA USP/TCC/Modelos/Testes/crisk_geral.csv', delimiter=',')\n",
    "crisk=crisk[['person_age','person_income','loan_amnt','loan_percent_income','cb_person_cred_hist_length',\n",
    "                         'loan_status']]\n",
    "crisk.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise descritiva com gráficos\n",
    "sns.set_theme(font_scale=1.3, rc={'figure.figsize': (20,20)})\n",
    "eixo = crisk.hist(bins=20, color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando variáveis preditoras e alvo\n",
    "X = crisk.iloc[:, :5].values\n",
    "y = crisk.iloc[:, 5:6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo o dataset entre treino e teste:\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora seguiremos por dois caminhos:\n",
    "- Caminho 1 - Base normalizada sem balancear\n",
    "- Caminho 2 - Base normalizada balanceada\n",
    "\n",
    "O intuito é treinar o modelo dessas duas formas e testar em uma mesma base de treino para comparar o desempenho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caminho 1 - Treinando modelo em base desbalanceada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_geral_des = X_train\n",
    "X_test_geral_des = X_test\n",
    "y_train_geral_des = y_train\n",
    "y_test_geral_des = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a normalização Min-Max apenas às características\n",
    "scaler = MinMaxScaler()\n",
    "X_train_geral_des_scaled = scaler.fit_transform(X_train_geral_des)\n",
    "X_test_geral_des_scaled = scaler.transform(X_test_geral_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Func_Log_geral_des = LogisticRegression(random_state=0, max_iter=500)\n",
    "Func_Log_geral_des.fit(X_train_geral_des, y_train_geral_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_geral_des = Func_Log_geral_des.predict(X_test_geral_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_geral_des, prev_geral_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_geral_des, prev_geral_des))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caminho 2 - Treinando o modelo em base balanceada (usando Oversempling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_geral_bal = X_train\n",
    "X_test_geral_bal = X_test\n",
    "y_train_geral_bal = y_train\n",
    "y_test_geral_bal = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a normalização Min-Max apenas às características\n",
    "scaler = MinMaxScaler()\n",
    "X_train_geral_bal_scaled = scaler.fit_transform(X_train_geral_bal)\n",
    "X_test_geral_bal_scaled = scaler.transform(X_test_geral_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Func_Log_geral_bal = LogisticRegression(random_state=0, max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um objeto RandomOverSampler para ajustar os pesos das classes\n",
    "\n",
    "ros_geral_balanc = RandomOverSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar o balanceamento de classes apenas no conjunto de treinamento\n",
    "\n",
    "X_train_resampled, y_train_resampled = ros_geral_balanc.fit_resample(X_train_geral_bal, y_train_geral_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.value_counts(y_train_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Func_Log_geral_bal.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar o mesmo na balanceada e desbalanceada\n",
    "prev_bal = Func_Log_geral_bal.predict(X_test_geral_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_geral_bal, prev_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_geral_bal, prev_bal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caminho 2.1 - Treinando o modelo em base balanceada (usando Undersempling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_geral_bal_under = X_train\n",
    "X_test_geral_bal_under = X_test\n",
    "y_train_geral_bal_under = y_train\n",
    "y_test_geral_bal_under = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a normalização Min-Max apenas às características\n",
    "scaler = MinMaxScaler()\n",
    "X_train_geral_bal_under_scaled = scaler.fit_transform(X_train_geral_bal_under)\n",
    "X_test_geral_bal_under_scaled = scaler.transform(X_test_geral_bal_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Func_Log_geral_bal_under = LogisticRegression(random_state=0, max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um objeto RandomOverSampler para ajustar os pesos das classes\n",
    "\n",
    "ros_geral_balanc_under = RandomUnderSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar o balanceamento de classes apenas no conjunto de treinamento\n",
    "\n",
    "X_train_resampled_under, y_train_resampled_under = ros_geral_balanc_under.fit_resample(X_train_geral_bal_under, y_train_geral_bal_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.value_counts(y_train_resampled_under))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Func_Log_geral_bal_under.fit(X_train_resampled_under, y_train_resampled_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar o mesmo na balanceada e desbalanceada\n",
    "prev_bal = Func_Log_geral_bal_under.predict(X_test_geral_bal_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_geral_bal_under, prev_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_geral_bal_under, prev_bal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste momento, estou dividindo a base em subcategorias e aplicando o modelo treinado anteriormente, tanto em base desbalanceada quanto em base balanceada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categoria A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crisk = pd.read_csv('C:/Users/AMD/Desktop/DESKTOP ANTIGA/Área de trabalho/Leandro/MBA USP/TCC/Modelos/Testes/crisk_geral.csv', delimiter=',')\n",
    "df_crisk_subcat=pd.DataFrame(crisk[['person_age','person_income','loan_amnt','loan_percent_income','cb_person_cred_hist_length','loan_grade',\n",
    "                         'loan_status']])\n",
    "df_crisk_subcat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subcat_A = pd.DataFrame(df_crisk_subcat.query('loan_grade ==\"A\"'))\n",
    "cat_A = subcat_A[['person_age','person_income','loan_amnt','loan_percent_income','cb_person_cred_hist_length',\n",
    "                         'loan_status']]\n",
    "cat_A.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_A.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando variáveis preditoras e alvo\n",
    "X_sub_A = cat_A.iloc[:, :5].values\n",
    "y_sub_A = cat_A.iloc[:, 5:6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo o dataset entre treino e teste:\n",
    "\n",
    "X_sub_A_train, X_sub_A_test, y_sub_A_train, y_sub_A_test = train_test_split(X_sub_A, y_sub_A, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categoria A desbalanceada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A_des = X_sub_A_train\n",
    "X_test_A_des = X_sub_A_test\n",
    "y_train_A_des = y_sub_A_train\n",
    "y_test_A_des = y_sub_A_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a normalização Min-Max apenas às características\n",
    "scaler = MinMaxScaler()\n",
    "X_train_A_des_scaled = scaler.fit_transform(X_train_A_des)\n",
    "X_test_A_des_scaled = scaler.transform(X_test_A_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Func_Log_A_des = LogisticRegression(random_state=0, max_iter=500)\n",
    "Func_Log_A_des.fit(X_train_A_des, y_train_A_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_A_des = Func_Log_A_des.predict(X_test_A_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_A_des, prev_A_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_A_des, prev_A_des))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categoria A Balanceada (Oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A_bal = X_sub_A_train\n",
    "X_test_A_bal = X_sub_A_test\n",
    "y_train_A_bal = y_sub_A_train\n",
    "y_test_A_bal = y_sub_A_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a normalização Min-Max apenas às características\n",
    "scaler = MinMaxScaler()\n",
    "X_train_A_bal_scaled = scaler.fit_transform(X_train_A_bal)\n",
    "X_test_A_bal_scaled = scaler.transform(X_test_A_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Func_Log_A_bal = LogisticRegression(random_state=0, max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um objeto RandomOverSampler para ajustar os pesos das classes\n",
    "\n",
    "ros_A_balanc = RandomOverSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar o balanceamento de classes apenas no conjunto de treinamento\n",
    "\n",
    "X_train_resampled_A, y_train_resampled_A = ros_A_balanc.fit_resample(X_train_A_bal, y_train_A_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Func_Log_A_bal.fit(X_train_resampled_A, y_train_resampled_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar o mesmo na balanceada e desbalanceada\n",
    "prev_bal_A = Func_Log_A_bal.predict(X_test_A_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_A_bal, prev_bal_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_A_bal, prev_bal_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categoria B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crisk = pd.read_csv('C:/Users/AMD/Desktop/DESKTOP ANTIGA/Área de trabalho/Leandro/MBA USP/TCC/Modelos/Testes/crisk_geral.csv', delimiter=',')\n",
    "df_crisk_subcat=pd.DataFrame(crisk[['person_age','person_income','loan_amnt','loan_percent_income','cb_person_cred_hist_length','loan_grade',\n",
    "                         'loan_status']])\n",
    "df_crisk_subcat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subcat_B = pd.DataFrame(df_crisk_subcat.query('loan_grade ==\"B\"'))\n",
    "cat_B = subcat_B[['person_age','person_income','loan_amnt','loan_percent_income','cb_person_cred_hist_length',\n",
    "                         'loan_status']]\n",
    "cat_B.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_B.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando variáveis preditoras e alvo\n",
    "X_sub_B = cat_B.iloc[:, :5].values\n",
    "y_sub_B = cat_B.iloc[:, 5:6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo o dataset entre treino e teste:\n",
    "\n",
    "X_sub_B_train, X_sub_B_test, y_sub_B_train, y_sub_B_test = train_test_split(X_sub_B, y_sub_B, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categoria B desbalanceada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_B_des = X_sub_B_train\n",
    "X_test_B_des = X_sub_B_test\n",
    "y_train_B_des = y_sub_B_train\n",
    "y_test_B_des = y_sub_B_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a normalização Min-Max apenas às características\n",
    "scaler = MinMaxScaler()\n",
    "X_train_B_des_scaled = scaler.fit_transform(X_train_B_des)\n",
    "X_test_B_des_scaled = scaler.transform(X_test_B_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Func_Log_B_des = LogisticRegression(random_state=0, max_iter=500)\n",
    "Func_Log_B_des.fit(X_train_B_des, y_train_B_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_B_des = Func_Log_B_des.predict(X_test_B_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_B_des, prev_B_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_B_des, prev_B_des))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categoria B balanceada (Oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_B_bal = X_sub_B_train\n",
    "X_test_B_bal = X_sub_B_test\n",
    "y_train_B_bal = y_sub_B_train\n",
    "y_test_B_bal = y_sub_B_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a normalização Min-Max apenas às características\n",
    "scaler = MinMaxScaler()\n",
    "X_train_B_bal_scaled = scaler.fit_transform(X_train_B_bal)\n",
    "X_test_B_bal_scaled = scaler.transform(X_test_B_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Func_Log_B_bal = LogisticRegression(random_state=0, max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um objeto RandomOverSampler para ajustar os pesos das classes\n",
    "\n",
    "ros_B_balanc = RandomOverSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar o balanceamento de classes apenas no conjunto de treinamento\n",
    "\n",
    "X_train_resampled_B, y_train_resampled_B = ros_B_balanc.fit_resample(X_train_B_bal, y_train_B_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Func_Log_B_bal.fit(X_train_resampled_B, y_train_resampled_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar o mesmo na balanceada e desbalanceada\n",
    "prev_bal_B = Func_Log_B_bal.predict(X_test_B_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_B_bal, prev_bal_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_B_bal, prev_bal_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categoria C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crisk = pd.read_csv('C:/Users/AMD/Desktop/DESKTOP ANTIGA/Área de trabalho/Leandro/MBA USP/TCC/Modelos/Testes/crisk_geral.csv', delimiter=',')\n",
    "df_crisk_subcat=pd.DataFrame(crisk[['person_age','person_income','loan_amnt','loan_percent_income','cb_person_cred_hist_length','loan_grade',\n",
    "                         'loan_status']])\n",
    "df_crisk_subcat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subcat_C = pd.DataFrame(df_crisk_subcat.query('loan_grade ==\"C\"'))\n",
    "cat_C = subcat_C[['person_age','person_income','loan_amnt','loan_percent_income','cb_person_cred_hist_length',\n",
    "                         'loan_status']]\n",
    "cat_C.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_C.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando variáveis preditoras e alvo\n",
    "X_sub_C = cat_C.iloc[:, :5].values\n",
    "y_sub_C = cat_C.iloc[:, 5:6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo o dataset entre treino e teste:\n",
    "\n",
    "X_sub_C_train, X_sub_C_test, y_sub_C_train, y_sub_C_test = train_test_split(X_sub_C, y_sub_C, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categoria C desbalanceada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_C_des = X_sub_C_train\n",
    "X_test_C_des = X_sub_C_test\n",
    "y_train_C_des = y_sub_C_train\n",
    "y_test_C_des = y_sub_C_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a normalização Min-Max apenas às características\n",
    "scaler = MinMaxScaler()\n",
    "X_train_C_des_scaled = scaler.fit_transform(X_train_C_des)\n",
    "X_test_C_des_scaled = scaler.transform(X_test_C_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Func_Log_C_des = LogisticRegression(random_state=0, max_iter=500)\n",
    "Func_Log_C_des.fit(X_train_C_des, y_train_C_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_C_des = Func_Log_C_des.predict(X_test_C_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_C_des, prev_C_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_C_des, prev_C_des))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categoria C balanceada (Oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_C_bal = X_sub_C_train\n",
    "X_test_C_bal = X_sub_C_test\n",
    "y_train_C_bal = y_sub_C_train\n",
    "y_test_C_bal = y_sub_C_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a normalização Min-Max apenas às características\n",
    "scaler = MinMaxScaler()\n",
    "X_train_C_bal_scaled = scaler.fit_transform(X_train_C_bal)\n",
    "X_test_C_bal_scaled = scaler.transform(X_test_C_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Func_Log_C_bal = LogisticRegression(random_state=0, max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um objeto RandomOverSampler para ajustar os pesos das classes\n",
    "\n",
    "ros_C_balanc = RandomOverSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar o balanceamento de classes apenas no conjunto de treinamento\n",
    "\n",
    "X_train_resampled_C, y_train_resampled_C = ros_C_balanc.fit_resample(X_train_C_bal, y_train_C_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Func_Log_C_bal.fit(X_train_resampled_C, y_train_resampled_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar o mesmo na balanceada e desbalanceada\n",
    "prev_bal_C = Func_Log_C_bal.predict(X_test_C_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_C_bal, prev_bal_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_C_bal, prev_bal_C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categoria D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crisk = pd.read_csv('C:/Users/AMD/Desktop/DESKTOP ANTIGA/Área de trabalho/Leandro/MBA USP/TCC/Modelos/Testes/crisk_geral.csv', delimiter=',')\n",
    "df_crisk_subcat=pd.DataFrame(crisk[['person_age','person_income','loan_amnt','loan_percent_income','cb_person_cred_hist_length','loan_grade',\n",
    "                         'loan_status']])\n",
    "df_crisk_subcat.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subcat_D = pd.DataFrame(df_crisk_subcat.query('loan_grade ==\"D\"'))\n",
    "cat_D = subcat_D[['person_age','person_income','loan_amnt','loan_percent_income','cb_person_cred_hist_length',\n",
    "                         'loan_status']]\n",
    "cat_D.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_D.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando variáveis preditoras e alvo\n",
    "X_sub_D = cat_D.iloc[:, :5].values\n",
    "y_sub_D = cat_D.iloc[:, 5:6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo o dataset entre treino e teste:\n",
    "\n",
    "X_sub_D_train, X_sub_D_test, y_sub_D_train, y_sub_D_test = train_test_split(X_sub_D, y_sub_D, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categoria D desbalanceada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_D_des = X_sub_D_train\n",
    "X_test_D_des = X_sub_D_test\n",
    "y_train_D_des = y_sub_D_train\n",
    "y_test_D_des = y_sub_D_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a normalização Min-Max apenas às características\n",
    "scaler = MinMaxScaler()\n",
    "X_train_D_des_scaled = scaler.fit_transform(X_train_D_des)\n",
    "X_test_D_des_scaled = scaler.transform(X_test_D_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Func_Log_D_des = LogisticRegression(random_state=0, max_iter=500)\n",
    "Func_Log_D_des.fit(X_train_D_des, y_train_D_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_D_des = Func_Log_D_des.predict(X_test_D_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_D_des, prev_D_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_D_des, prev_D_des))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categoria D balanceada (Oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_D_bal = X_sub_D_train\n",
    "X_test_D_bal = X_sub_D_test\n",
    "y_train_D_bal = y_sub_D_train\n",
    "y_test_D_bal = y_sub_D_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a normalização Min-Max apenas às características\n",
    "scaler = MinMaxScaler()\n",
    "X_train_D_bal_scaled = scaler.fit_transform(X_train_D_bal)\n",
    "X_test_D_bal_scaled = scaler.transform(X_test_D_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Func_Log_D_bal = LogisticRegression(random_state=0, max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um objeto RandomOverSampler para ajustar os pesos das classes\n",
    "\n",
    "ros_D_balanc = RandomOverSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar o balanceamento de classes apenas no conjunto de treinamento\n",
    "\n",
    "X_train_resampled_D, y_train_resampled_D = ros_D_balanc.fit_resample(X_train_D_bal, y_train_D_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Func_Log_D_bal.fit(X_train_resampled_D, y_train_resampled_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar o mesmo na balanceada e desbalanceada\n",
    "prev_bal_D = Func_Log_D_bal.predict(X_test_D_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_D_bal, prev_bal_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_D_bal, prev_bal_D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categoria D (Undersampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_D_bal_under = X_sub_D_train\n",
    "X_test_D_bal_under = X_sub_D_test\n",
    "y_train_D_bal_under = y_sub_D_train\n",
    "y_test_D_bal_under = y_sub_D_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a normalização Min-Max apenas às características\n",
    "scaler = MinMaxScaler()\n",
    "X_train_D_bal_under_scaled = scaler.fit_transform(X_train_D_bal_under)\n",
    "X_test_D_bal_under_scaled = scaler.transform(X_test_D_bal_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Func_Log_D_bal_under = LogisticRegression(random_state=0, max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um objeto RandomOverSampler para ajustar os pesos das classes\n",
    "\n",
    "ros_D_balanc_under = RandomUnderSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar o balanceamento de classes apenas no conjunto de treinamento\n",
    "\n",
    "X_train_resampled_D_under, y_train_resampled_D_under = ros_D_balanc_under.fit_resample(X_train_D_bal_under, y_train_D_bal_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Func_Log_D_bal_under.fit(X_train_resampled_D_under, y_train_resampled_D_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar o mesmo na balanceada e desbalanceada\n",
    "prev_bal_D_under = Func_Log_D_bal_under.predict(X_test_D_bal_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_D_bal_under, prev_bal_D_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_D_bal_under, prev_bal_D_under))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categoria E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crisk = pd.read_csv('C:/Users/AMD/Desktop/DESKTOP ANTIGA/Área de trabalho/Leandro/MBA USP/TCC/Modelos/Testes/crisk_geral.csv', delimiter=',')\n",
    "df_crisk_subcat=pd.DataFrame(crisk[['person_age','person_income','loan_amnt','loan_percent_income','cb_person_cred_hist_length','loan_grade',\n",
    "                         'loan_status']])\n",
    "df_crisk_subcat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subcat_E = pd.DataFrame(df_crisk_subcat.query('loan_grade ==\"E\"'))\n",
    "cat_E = subcat_E[['person_age','person_income','loan_amnt','loan_percent_income','cb_person_cred_hist_length',\n",
    "                         'loan_status']]\n",
    "cat_E.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_E.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando variáveis preditoras e alvo\n",
    "X_sub_E = cat_E.iloc[:, :5].values\n",
    "y_sub_E = cat_E.iloc[:, 5:6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo o dataset entre treino e teste:\n",
    "\n",
    "X_sub_E_train, X_sub_E_test, y_sub_E_train, y_sub_E_test = train_test_split(X_sub_E, y_sub_E, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categoria E desbalanceada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_E_des = X_sub_E_train\n",
    "X_test_E_des = X_sub_E_test\n",
    "y_train_E_des = y_sub_E_train\n",
    "y_test_E_des = y_sub_E_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a normalização Min-Max apenas às características\n",
    "scaler = MinMaxScaler()\n",
    "X_train_E_des_scaled = scaler.fit_transform(X_train_E_des)\n",
    "X_test_E_des_scaled = scaler.transform(X_test_E_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Func_Log_E_des = LogisticRegression(random_state=0, max_iter=500)\n",
    "Func_Log_E_des.fit(X_train_E_des, y_train_E_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_E_des = Func_Log_E_des.predict(X_test_E_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_E_des, prev_E_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_E_des, prev_E_des))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categoria E balanceada (Oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_E_bal = X_sub_E_train\n",
    "X_test_E_bal = X_sub_E_test\n",
    "y_train_E_bal = y_sub_E_train\n",
    "y_test_E_bal = y_sub_E_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a normalização Min-Max apenas às características\n",
    "scaler = MinMaxScaler()\n",
    "X_train_E_bal_scaled = scaler.fit_transform(X_train_E_bal)\n",
    "X_test_E_bal_scaled = scaler.transform(X_test_E_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Func_Log_E_bal = LogisticRegression(random_state=0, max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um objeto RandomOverSampler para ajustar os pesos das classes\n",
    "\n",
    "ros_E_balanc = RandomOverSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar o balanceamento de classes apenas no conjunto de treinamento\n",
    "\n",
    "X_train_resampled_E, y_train_resampled_E = ros_E_balanc.fit_resample(X_train_E_bal, y_train_E_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Func_Log_E_bal.fit(X_train_resampled_E, y_train_resampled_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar o mesmo na balanceada e desbalanceada\n",
    "prev_bal_E = Func_Log_E_bal.predict(X_test_E_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_E_bal, prev_bal_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_E_bal, prev_bal_E))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categoria E (Undersampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_E_bal_under = X_sub_E_train\n",
    "X_test_E_bal_under = X_sub_E_test\n",
    "y_train_E_bal_under = y_sub_E_train\n",
    "y_test_E_bal_under = y_sub_E_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a normalização Min-Max apenas às características\n",
    "scaler = MinMaxScaler()\n",
    "X_train_E_bal_under_scaled = scaler.fit_transform(X_train_E_bal_under)\n",
    "X_test_E_bal_under_scaled = scaler.transform(X_test_E_bal_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Func_Log_E_bal_under = LogisticRegression(random_state=0, max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um objeto RandomOverSampler para ajustar os pesos das classes\n",
    "\n",
    "ros_E_balanc_under = RandomUnderSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar o balanceamento de classes apenas no conjunto de treinamento\n",
    "\n",
    "X_train_resampled_E_under, y_train_resampled_E_under = ros_E_balanc_under.fit_resample(X_train_E_bal_under, y_train_E_bal_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Func_Log_E_bal_under.fit(X_train_resampled_E_under, y_train_resampled_E_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar o mesmo na balanceada e desbalanceada\n",
    "prev_bal_E_under = Func_Log_E_bal_under.predict(X_test_E_bal_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_E_bal_under, prev_bal_E_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_E_bal_under, prev_bal_E_under))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
